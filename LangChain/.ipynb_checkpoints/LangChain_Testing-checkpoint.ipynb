{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc3f82f",
   "metadata": {},
   "source": [
    "# *Setup*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a8d3cf",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5af57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "# Integrations\n",
    "from langchain.llms import GPT4All\n",
    "\n",
    "# Misc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387d7d5",
   "metadata": {},
   "source": [
    "## Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f6e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SerpAPI for search engine queries\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"6d000f9babc9c617854344a947553d8946612c6b94512002f98bdb3bf78511ce\"\n",
    "\n",
    "# OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3a7da",
   "metadata": {},
   "source": [
    "## Langchain Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73357b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:/Users/Destr/AppData/Local/nomic.ai/GPT4All/GPT4All-13B-snoozy.ggmlv3.q4_0.bin\n"
     ]
    }
   ],
   "source": [
    "# llm = OpenAI(temperature=0)\n",
    "\n",
    "llm = GPT4All(model=\"C:/Users/Destr/AppData/Local/nomic.ai/GPT4All/GPT4All-13B-snoozy.ggmlv3.q4_0.bin\",\n",
    "             n_ctx = 4096,\n",
    "             n_threads = 4,\n",
    "             temp = 0.1)\n",
    "\n",
    "# llm = GPT4All(model=\"C:/Users/Destr/AppData/Local/nomic.ai/GPT4All/ggml-gpt4all-j-v1.3-groovy.bin\",\n",
    "#              n_ctx = 1024,\n",
    "#              n_threads = 4)\n",
    "\n",
    "# llm = GPT4All(model=\"C:/Users/Destr/AppData/Local/nomic.ai/GPT4All/nous-hermes-13b.ggmlv3.q4_0.bin\",\n",
    "#              n_ctx = 4096,\n",
    "#              n_threads = 4,\n",
    "#              temp = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32175ded",
   "metadata": {},
   "source": [
    "# *Using Prompt Templates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0648f8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes colorful socks?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494471c",
   "metadata": {},
   "source": [
    "## Integrating Prompt Templates with LLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e658410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rainbow Sock Co.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nRainbow Sock Co.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain.run(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f09a896",
   "metadata": {},
   "source": [
    "# *Using Agents*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14cebc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "# tools = load_tools([\"serpapi\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Let's test it out!\n",
    "# agent.run(\"How many goals has Lionel Messi scored in his career? Take the logarithm of that number.\")\n",
    "agent.run(\"What was the high temperature in SF yesterday in Fahrenheit? What is that number raised to the .023 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7bdea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
